AI-powered mock interviewer to assess Excel skills with a structured, interview-style flow.
It asks 6 questions across skills (Aggregation, Lookups, Efficiency, etc.), evaluates answers intelligently, adapts difficulty, and ends with a constructive report.

Built as a hybrid Product/Engineering solution: deterministic grading for formulas/tables, LLM-assisted grading for short text, and robust agentic state management for a realistic interview.

âœ¨ Features

Structured flow: intro â†’ questions (with hints) â†’ summary

Type-guarding: prevents accidental progress on wrong answer types (formula / value / table / text)

Deterministic grading:

Formulas via rule checks (e.g., SUMIFS, INDEX/MATCH, XLOOKUP)

Tables/values via pandas evaluation

LLM-assisted grading (optional): short text answers with rubric

Adaptive difficulty: moves between E/M/H based on recent scores

Hint penalty: default âˆ’0.5 per hint, applied to the final score

Report: banding, per-skill %, strengths, gaps, suggested drills

Admin metrics: total answers, avg score, per-skill averages

Front-end UX: shows Expected vs Detected type + disables submit on mismatch

ğŸ§­ Monorepo Layout
excel-mock-interviewer-advanced/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI app (routes, type-guard, eval flow)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py             # Interview state, hints, adaptivity, penalties
â”‚   â”‚   â”‚   â”œâ”€â”€ report.py            # Summary report (bands, skills, drills)
â”‚   â”‚   â”‚   â””â”€â”€ llm.py               # Optional LLM grading (text only)
â”‚   â”‚   â”œâ”€â”€ grading/
â”‚   â”‚   â”‚   â”œâ”€â”€ formula_rules.py     # Formula checks (SUMIFS, XLOOKUP, INDEX/MATCH)
â”‚   â”‚   â”‚   â””â”€â”€ pandas_eval.py       # Value/table evaluation via pandas
â”‚   â”‚   â”œâ”€â”€ questions/
â”‚   â”‚   â”‚   â””â”€â”€ bank.py              # Question bank
â”‚   â”‚   â””â”€â”€ db/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ models.py            # Interview, Answer
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md (optional)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ index.tsx                # UI with Expected/Detected type, hints & logs
â”‚   â”œâ”€â”€ lib/api.ts                   # API client (hardened fetch)
â”‚   â”œâ”€â”€ package.json                 # Next.js 14
â”‚   â”œâ”€â”€ next.config.js               # (supports static export if you choose)
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ render.yaml                      # (optional) Render blueprint
â””â”€â”€ README.md                        # â† You are here

ğŸ§° Tech Stack & Rationale

Backend: FastAPI (simple, fast, great DX)

Grading: Rule-based for formula/value/table (deterministic), LLM for short text only

LLM: OpenAI (pluggable via env); if no key â†’ graceful fallback

DB: SQLite in PoC; SQLAlchemy models; easy to swap later

Frontend: Next.js 14 + React 18, simple single-page UI, strong UX for answer types

Hosting:

Backend â†’ Render (Web Service)

Frontend â†’ Vercel/Netlify (or Render Static Site)

âš™ï¸ Environment Variables

Backend (excel-mock-interviewer-advanced/backend/.env)

Never commit secrets. Create locally or on the host.

# Optional: turns LLM grading ON when present
OPENAI_API_KEY=sk-...

# Optional: model for short-text grading
LLM_MODEL=gpt-4o-mini

# DB (defaults to local SQLite if omitted)
DB_URL=sqlite:///./data.db


Frontend (excel-mock-interviewer-advanced/frontend/.env.local)

# Point the UI to your backend
NEXT_PUBLIC_API_BASE=http://127.0.0.1:8000

ğŸš€ Local Development
1) Backend
cd excel-mock-interviewer-advanced/backend
python -m venv .venv
# Windows PowerShell: .\.venv\Scripts\Activate.ps1
# macOS/Linux:       source .venv/bin/activate

pip install -r requirements.txt
uvicorn app.main:app --host 127.0.0.1 --port 8000
# Health: http://127.0.0.1:8000/health  => {"ok":true,"version":"0.2.0"}
# Docs:   http://127.0.0.1:8000/docs

2) Frontend
cd excel-mock-interviewer-advanced/frontend
npm install
# set NEXT_PUBLIC_API_BASE in .env.local (see above)
npm run dev
# UI: http://localhost:3000

ğŸ”Œ API Endpoints (Backend)

GET /health â†’ simple health JSON

POST /start â†’ { interview_id, question }

Body: { "candidate_email": "optional@user.com" }

POST /answer â†’ evaluation + next question

Body:

Common: { "interview_id", "question_id" }

For hint: add "want_hint": true

For formula/value/text: add "answer_text": "..."

For table: add "answer_table": [ { ... }, ... ]

Response always includes: score, feedback, done, and either next_question or summary.

GET /report/{interview_id} â†’ final summary (band, per-skill, strengths, gaps, drills)

GET /admin/metrics â†’ admin stats (totals, averages, per-skill)

ğŸ§  Scoring & Adaptivity

Type-Guard: if you submit a wrong type, you donâ€™t advance and get a gentle reminder.

Hints: you can ask for a hint anytime; each hint costs âˆ’0.5 from that questionâ€™s final score.

Adaptive difficulty: recent scores steer the next question:

last two â‰¥ 4/5 â†’ target Hard

last one â‰¤ 2/5 â†’ target Easy

else â†’ Medium

LLM grading (text): used only for short text questions. If OPENAI_API_KEY is absent, a rule-based fallback runs.

ğŸ§ª Quick Test (Curl)
# Start
curl -s -X POST http://127.0.0.1:8000/start -H "Content-Type: application/json" -d "{}"

# Example answer (formula)
curl -s -X POST http://127.0.0.1:8000/answer \
  -H "Content-Type: application/json" \
  -d '{"interview_id":"<from start>","question_id":"<qid>","answer_text":"=SUMIFS(D:D,A:A,\"East\",C:C,\"Pencil\")"}'

ğŸ§‘â€ğŸ’» Frontend UX Tips

Under each prompt youâ€™ll see: Expected: (formula/value/table/text) and a Detected badge that updates as you type.

Submit is disabled until your input matches the expected format.

Placeholders show valid examples (e.g., a sample formula or table JSON).

ğŸŒ Deployment
Backend (Render)

Root directory: excel-mock-interviewer-advanced/backend

Build command: pip install -r requirements.txt

Start command:

uvicorn app.main:app --host 0.0.0.0 --port $PORT


Env Vars: set OPENAI_API_KEY, LLM_MODEL, and (optionally) DB_URL

Instance: Free is fine for PoC (will sleep on idle)

Frontend (Vercel/Netlify/Render Static Site)

Root directory: excel-mock-interviewer-advanced/frontend

Env: set NEXT_PUBLIC_API_BASE to your backend URL (e.g., https://your-backend.onrender.com)

Build: next build

Start (SSR) or static export (optional):

If you choose static export, set next.config.js accordingly and use next export.

For SSR on Render, create a Node Web Service and run next start -p $PORT.

Keep frontend & backend in separate services. It simplifies environment variables and scaling.

ğŸ”’ Security

Never commit secrets (.env, API keys).

GitHub may block pushes if it detects keysâ€”rotate & remove from history if this happens.

Use Render/Vercel Environment Variables instead.

ğŸ“ˆ Cold-Start â†’ Improve Over Time

Start with a seed bank (this PoC).

Add parametric templates for new variants (change Reps/Items/Regions/Values).

Keep deterministic checks for formulas/tables; expand rubric prompts for text.

Add telemetry (e.g., hardest skills per cohort) to drive new drills.

ğŸ§¾ Sample Transcript (excerpt)
Agent: Hi! 6 questions in ~12 mins.
Q1 (Aggregation): East + Pencil total â€” Expected: formula
You: =SUMIFS(D:D,A:A,"East",C:C,"Pencil")
Agent: Formula accepted. (Score: 5)

Q2 (Aggregation): Total orders â€” Expected: value
You: 56
Agent: Correct numeric result. (Score: 5)

...
Agent: Interview complete. Band: Intermediate.
Summary: Aggregation 80% | Lookups 100% | Efficiency 40%
Drills: Practice more on: Efficiency

â“Troubleshooting

Frontend says â€œFailed to fetchâ€ â†’ check backend URL in NEXT_PUBLIC_API_BASE, backend running/healthy, and CORS.

Git push blocked (large files) â†’ donâ€™t commit .next/, node_modules/, .venv/, data.db (use .gitignore).

Git push blocked (secrets) â†’ remove keys from history, rotate key, push again.

Render start command wrong â†’ use uvicorn app.main:app --host 0.0.0.0 --port $PORT.

ğŸ“œ License

MIT â€” use, modify, and build on it.
Please keep attribution if you publish derivatives or demos.

Happy hiring! If youâ€™d like, I can also generate a concise Design Doc (2â€“3 pages) to attach alongside this repo.
